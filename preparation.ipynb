{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: 'Georgia', serif; text-align: center; font-size: 30px; color:rgb(52, 152, 219); text-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3)\">Préparation des données</h1>\n",
    "<br/>\n",
    "<br/>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: 'Georgia', serif; text-align: center; font-size: 25px; color: #3498db\">1- <u>reduction du nombre de variable de base_edu </u></h1>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastparquet\n",
    "!pip install rpy2\n",
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_learner_id</th>\n",
       "      <th>days_between_signup_and_first_activity</th>\n",
       "      <th>days_between_order_and_first_activity</th>\n",
       "      <th>first_theory_activity_date</th>\n",
       "      <th>days_between_first_and_last_activities</th>\n",
       "      <th>chapter_before_success_count</th>\n",
       "      <th>serie_before_success_count</th>\n",
       "      <th>quiz_before_success_count</th>\n",
       "      <th>theory_activities_total</th>\n",
       "      <th>weekly_study_objective</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_weeks_weekly_study_objective_reached_80pct</th>\n",
       "      <th>nb_weeks_weekly_study_objective_reached_75pct</th>\n",
       "      <th>nb_weeks_weekly_study_objective_reached_70pct</th>\n",
       "      <th>nb_weeks_weekly_study_objective_not_reached</th>\n",
       "      <th>nb_weeks_no_activity</th>\n",
       "      <th>nb_weeks_no_weekly_study_objective</th>\n",
       "      <th>pct_study_objective_reached</th>\n",
       "      <th>pct_study_objective_not_reached</th>\n",
       "      <th>pct_study_objective_no_activity</th>\n",
       "      <th>pct_no_objective_weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3838161406066513919</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-17 15:00:23.000000</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5829430568065349352</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-07 12:02:53.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7677180318050051984</td>\n",
       "      <td>787</td>\n",
       "      <td>788</td>\n",
       "      <td>2022-05-10 01:35:49.000000</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5150597998144597550</td>\n",
       "      <td>615</td>\n",
       "      <td>616</td>\n",
       "      <td>2024-04-18 04:56:03.262330</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>969323468959211246</td>\n",
       "      <td>169</td>\n",
       "      <td>170</td>\n",
       "      <td>2019-03-19 12:32:56.000000</td>\n",
       "      <td>554</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 477 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_learner_id  days_between_signup_and_first_activity  \\\n",
       "0   3838161406066513919                                      41   \n",
       "1   5829430568065349352                                       0   \n",
       "2   7677180318050051984                                     787   \n",
       "3  -5150597998144597550                                     615   \n",
       "4    969323468959211246                                     169   \n",
       "\n",
       "   days_between_order_and_first_activity first_theory_activity_date  \\\n",
       "0                                      0 2017-12-17 15:00:23.000000   \n",
       "1                                      0 2022-07-07 12:02:53.000000   \n",
       "2                                    788 2022-05-10 01:35:49.000000   \n",
       "3                                    616 2024-04-18 04:56:03.262330   \n",
       "4                                    170 2019-03-19 12:32:56.000000   \n",
       "\n",
       "   days_between_first_and_last_activities  chapter_before_success_count  \\\n",
       "0                                     265                             0   \n",
       "1                                      27                             0   \n",
       "2                                     295                             0   \n",
       "3                                     138                             0   \n",
       "4                                     554                             0   \n",
       "\n",
       "   serie_before_success_count  quiz_before_success_count  \\\n",
       "0                           3                          0   \n",
       "1                           0                          0   \n",
       "2                           0                          0   \n",
       "3                           0                          0   \n",
       "4                           0                          0   \n",
       "\n",
       "   theory_activities_total  weekly_study_objective  ...  \\\n",
       "0                        3                    <NA>  ...   \n",
       "1                       11                    <NA>  ...   \n",
       "2                       73                     240  ...   \n",
       "3                       75                    <NA>  ...   \n",
       "4                       41                     120  ...   \n",
       "\n",
       "   nb_weeks_weekly_study_objective_reached_80pct  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   nb_weeks_weekly_study_objective_reached_75pct  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   nb_weeks_weekly_study_objective_reached_70pct  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   nb_weeks_weekly_study_objective_not_reached  nb_weeks_no_activity  \\\n",
       "0                                            0                     0   \n",
       "1                                            0                     0   \n",
       "2                                            1                     0   \n",
       "3                                            0                     0   \n",
       "4                                            1                     0   \n",
       "\n",
       "   nb_weeks_no_weekly_study_objective  pct_study_objective_reached  \\\n",
       "0                                   1                          0.0   \n",
       "1                                   1                          0.0   \n",
       "2                                   0                          0.0   \n",
       "3                                   1                          0.0   \n",
       "4                                   0                          0.0   \n",
       "\n",
       "   pct_study_objective_not_reached  pct_study_objective_no_activity  \\\n",
       "0                              0.0                              0.0   \n",
       "1                              0.0                              0.0   \n",
       "2                            100.0                              0.0   \n",
       "3                              0.0                              0.0   \n",
       "4                            100.0                              0.0   \n",
       "\n",
       "   pct_no_objective_weeks  \n",
       "0                   100.0  \n",
       "1                   100.0  \n",
       "2                     0.0  \n",
       "3                   100.0  \n",
       "4                     0.0  \n",
       "\n",
       "[5 rows x 477 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#chemin de la Base de données\n",
    "url=\"C:/Users/damso/Documents/data/base_Edu.parquet\"\n",
    "base_Edu=pd.read_parquet(url)\n",
    "base_Edu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 477 entries, unique_learner_id to pct_no_objective_weeks\n",
      "dtypes: Int64(72), boolean(254), datetime64[us](1), float64(150)\n",
      "memory usage: 450.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(base_Edu.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de données compte donc 477 variables dont 72 de type Int, 254 de type boolean, 1 de type datetime et 150 de type float soit au total 254 variables qualitatives (**boolean**) et 221 variables quantitatives(**float + int** en excluant les identifiants) sans oublier la variable de type **datetime**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous commencons par épurer la base données avant de passer à la réduction de dimension. On s'intéressera aux valeurs manquantes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    404.000000\n",
       "mean       0.743390\n",
       "std        0.279055\n",
       "min        0.047720\n",
       "25%        0.666710\n",
       "50%        0.842345\n",
       "75%        0.918625\n",
       "max        1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value=(base_Edu.isnull().sum()/len(base_Edu))\n",
    "missing_value[missing_value>0]\n",
    "missing_value[missing_value>0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de données comporte donc 404 variables avec valeurs manquantes sur le total des 476 variables de la base ce qui n'est pas du tout négligeable. Voyons combien de valeurs manquantes at-on par type de variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48  variable de type int ont des valeurs manquantes\n",
      "103  variable de type float ont des valeurs manquantes\n",
      "253  variable de type boolean ont des valeurs manquantes\n",
      "0  variable de type datetime ont des valeurs manquantes\n"
     ]
    }
   ],
   "source": [
    "print(base_Edu.select_dtypes(\"int\").isnull().any().sum(),\" variables de type int ont des valeurs manquantes\")\n",
    "print(base_Edu.select_dtypes(\"float\").isnull().any().sum(),\" variables de type float ont des valeurs manquantes\")\n",
    "print(base_Edu.select_dtypes(\"boolean\").isnull().any().sum(),\" variables de type boolean ont des valeurs manquantes\")\n",
    "print(base_Edu.select_dtypes(\"datetime\").isnull().any().sum(),\" variables de type datetime ont des valeurs manquantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La seule variable de type datetime n'a donc pas de valeurs manquantes.  Analysons de plus près les proportions de valeurs manquantes des autres types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    253.000000\n",
       "mean       0.903116\n",
       "std        0.072136\n",
       "min        0.695085\n",
       "25%        0.837765\n",
       "50%        0.883305\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_bool=base_Edu.select_dtypes(\"boolean\").isnull().sum()/len(base_Edu)\n",
    "miss_bool[miss_bool>0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables de type boolean comporte pratiquement tous assez de valeurs manquantes avec un minimum de 69% et un maximum de 100% du total des observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs manquantes de la base ne sont pas complètement aléatoires. Elles ne sont pas pour la plupart le fruit d'une mauvaise collecte de données. La présence de valeurs manquantes dans cette base est due à diverses raisons notamment le fait que plusieurs individus de la base n'ont pas encore passé d'examen pour le permis. Plusieurs questions(variables) n'ont de sens que dans le cas où le premier examen est passé. Il y a donc une part d'information apporté par ces valeurs manquantes que nous devons inclure dans nos analyses. Pour les variables booléenne, nous pouvons régler ce prblème c'est à dire prendre en compte l'information apportée par ces valeurs manquantes en transformant les variables booléennes en variable catégorielles en considérant les valeurs manquantes comme une catégorie(True=1,False=0 et NA=2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(base_Edu.select_dtypes('category'))\n",
    "def encode_column_with_na(col):\n",
    "    mapping = {True: 1, False: 0, pd.NA: 2}  # Encoder les valeurs booléennes et <NA>\n",
    "    return col.map(mapping)\n",
    "colboo=base_Edu.select_dtypes(\"boolean\").columns\n",
    "for col in colboo:\n",
    "    base_Edu[col] = encode_column_with_na(base_Edu[col]).astype(\"category\")\n",
    "#base_Edu[\"is_first_exam_success\"].cat.categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passons maintenant aux variables quantitatives (int+float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    151.000000\n",
       "mean       0.475770\n",
       "std        0.292138\n",
       "min        0.047720\n",
       "25%        0.184915\n",
       "50%        0.483995\n",
       "75%        0.736010\n",
       "max        0.941710\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_quant=base_Edu.select_dtypes(include=[\"int\",\"float\"]).isnull().sum()/len(base_Edu)\n",
    "miss_quant[miss_quant>0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les variables quantitatives, la distribution des valeurs manquantes est plus étendue. On enregistre 151 variables quantitatives avec valeurs manquantes. On a un minimum de 4% et un maximum de 94% de valeurs manquantes par rapport au total d'observation(nous rappelons 200000 obervations). La nature des variables et la distribution des valeurs manquantes dans ce cas ne facilite pas la capture de l'information apportée par la présence de ces valeurs manquantes. On pourrait opter pour une imputation par KNN ou par imputation itérative (MICE) mais cela risque de modifier et significativement les corrélations existant déjà entre les variables introduisant ainsi un important biais et au vue de la taille de l'echantillon, cela demanderait un temps d'excution énorme. On choisit ici donc de procéder à une imputation par la médiane après suppression des variables avant un taux élevé de valeurs manquantes pour minimiser le biais. Cela permettra de ne pas trop distordre les distributions existentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    118.000000\n",
       "mean       0.054362\n",
       "std        0.074368\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.106310\n",
       "max        0.194530\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_quant[miss_quant<=0.20].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous choisissons le seuil de 20% de valeurs manquantes. Ce seuil nous parait raisonnable puisqu'il est relativement faible et n'entraine pas la suppression d'un grand nombre de variables quantitatives (118 sont conservées sur un total de 151)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppression des variables avec plus de 20% de valeurs manquantes\n",
    "base_Edu=base_Edu.drop(columns=miss_quant[miss_quant>0.20].index)\n",
    "#Imputation par la médiane\n",
    "col=base_Edu.select_dtypes(exclude='category').columns\n",
    "base_Edu[col] = base_Edu[col].fillna(base_Edu[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_Edu.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 372 entries, unique_learner_id to pct_no_objective_weeks\n",
      "dtypes: Int64(47), category(254), float64(71)\n",
      "memory usage: 237.5 MB\n"
     ]
    }
   ],
   "source": [
    "df1 = base_Edu.select_dtypes(exclude=['datetime64'])  # Colonnes non datetime64\n",
    "df2 = base_Edu.select_dtypes(include=['datetime64']) #colonnes datetime\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sauvegarde des données sans var date\n",
    "df1.to_parquet('data_Edu.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus aucune valeur manquante. La base de données enfin prête, on peut passer aux opérations de réduction de dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<p style=\"font-family: 'Georgia', serif; text-align: center;color:rgb(47, 99, 220);font-size: 30px\">\n",
    "<u>\n",
    "Réduction de dimension</u>\n",
    "</p>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etant donnée la dimension de la base de données( beaucoup de variables), ce sera très complexe voir impossible de faire des analyses ou entrainer un modèle directement sur cette base. Il est donc important voir optimale de faire au préalable une réduction de dimension. Pour ce faire, nous allons utiliser différentes approches de réduction de dimension, faire des comparaisons puis retenir la meilleure approche dans ce cas. Il s'agira principalement de faire une **analyse enn composante principale (ACP)** , une **FAMD** et utiliser **un autoencodeur**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<p style=\"font-family: 'Georgia', serif; text-align: center;font-size: 25px\">\n",
    "<u>\n",
    "1- Analyse en composantes principales (ACP) </u>\n",
    "</p>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<p style=\"font-family: 'Georgia', serif; text-align: center;font-size: 25px\">\n",
    "<u>\n",
    "2- Analyse Factorielle des Composantes Mixtes (FAMD) </u>\n",
    "</p>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10000 entries, 119737 to 162886\n",
      "Columns: 372 entries, unique_learner_id to pct_no_objective_weeks\n",
      "dtypes: Int64(47), category(254), float64(71)\n",
      "memory usage: 12.0 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df= pd.read_parquet(\"data_Edu.parquet\")\n",
    "df_sample=df.sample(n=10000, random_state=42)\n",
    "df_sample.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import io\n",
    "os.environ['R_HOME'] = r\"C:\\Program Files\\R\\R-4.4.2\"  # Exemple : '/home/user/anaconda3/envs/mon_env/lib/R'\n",
    "os.environ['R_LIBS_USER'] = r\"C:\\Users\\HP\\AppData\\Local\\R\\win-library\\4.4\"\n",
    "# Optionnel : Ajouter le chemin des DLLs de R pour éviter des erreurs de chargement\n",
    "#os.environ['PATH'] += os.pathsep + r\"C:\\Program Files\\R\\R-4.4.2\\bin\\x64\"\n",
    "\n",
    "# Importer rpy2 et activer la conversion pandas2ri\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "# ro.r('library(ggplot2)')\n",
    "# ro.r('library(FactoMineR)')\n",
    "\n",
    "# Charger les données dans R\n",
    "\n",
    "base_AE = base_AE.reset_index(drop=True)\n",
    "\n",
    "ro.globalenv['data'] = pandas2ri.py2rpy(base_AE)\n",
    "\n",
    "# Récupérer les colonnes de type 'category'\n",
    "category_columns = base_AE.select_dtypes(include=['category']).columns\n",
    "\n",
    "# Convertir les noms des colonnes en liste pour les passer à R\n",
    "ro.globalenv['category_columns'] = category_columns.tolist()\n",
    "\n",
    "\n",
    "ro.r('''\n",
    "    # Vérifier si les bibliothèques sont installées et les charger\n",
    "    #if (!require(\"ggplot2\")) install.packages(\"ggplot2\")\n",
    "    #if (!require(\"FactoMineR\")) install.packages(\"FactoMineR\")\n",
    "    #if (!require(\"factoextra\")) install.packages(\"factoextra\")\n",
    "     \n",
    "    # Récupérer les noms des colonnes de type 'category' de Python\n",
    "    category_columns <- as.character(category_columns)\n",
    "\n",
    "    # Appliquer la conversion en factor sur ces colonnes\n",
    "    data[category_columns] <- lapply(data[category_columns], as.factor)\n",
    "    # Afficher les niveaux de chaque variable factor\n",
    "    # Filtrer uniquement les variables de type factor\n",
    "    library(RColorBrewer)\n",
    "    library(ggplot2)\n",
    "    library(FactoMineR)\n",
    "    library(factoextra)\n",
    "    # Exemple pour toutes les variables qualitatives\n",
    "    result <- FAMD(data, ncp = 2, graph = FALSE)\n",
    "\n",
    "    # Sauvegarder le graphique des individus --- ne marche pas\n",
    "    #png(\"famd_individus.png\", width = 800, height = 600)\n",
    "    #fviz_famd_ind(result, repel = FALSE) # Graphe des individus\n",
    "    #dev.off().\n",
    "    # Récupérer les coordonnées des individus dans l'analyse FAMD\n",
    "    ind_coords <- result$ind$coord\n",
    "\n",
    "    # Si tu veux aussi récupérer les labels associés\n",
    "    ind_labels <- rownames(ind_coords)\n",
    "\n",
    "    # Utiliser ggplot2 pour créer un graphique personnalisé\n",
    "    library(ggrepel)\n",
    "    library(ggplot2)\n",
    "    ind_coords_df <- as.data.frame(ind_coords)\n",
    "    ind_coords_df$label <- ind_labels\n",
    "\n",
    "    graph <- ggplot(ind_coords_df, aes(x = Dim.1, y = Dim.2, label = label)) +\n",
    "        geom_point() +  # Ajouter les points\n",
    "        geom_text_repel() +  # Ajouter les étiquettes de texte avec gestion des collisions\n",
    "        labs(title = \"Graphique des individus - FAMD\") +\n",
    "        theme_bw()\n",
    "    # Enregistrer le graphique dans un fichier PNG dans ton répertoire de travail\n",
    "    ggsave(\"famd_individuals_graph.png\", plot = graph, width = 10, height = 8, dpi = 300)\n",
    "\n",
    "\n",
    "    # Sauvegarder le graphique des variables --- ne marche pas\n",
    "    #png(\"famd_variables.png\", width = 800, height = 600)\n",
    "    graph_var <- fviz_famd_var(result, repel = TRUE) # Graphe des variables\n",
    "    ggsave(\"famd_variables_graph.png\", plot = graph_var, width = 10, height = 8, dpi = 300)\n",
    "    #dev.off()\n",
    "\n",
    "    #res <-summary(result)\n",
    "    #result_df <- as.data.frame(result$ind$coord) # Récupérer les coordonnées des individus\n",
    "    #result_var_df <- as.data.frame(result$var$coord) # Récupérer les coordonnées des individus\n",
    "''')\n",
    "# #Récupérer les résultats en Python\n",
    "# result_df = ro.r('result_df')\n",
    "# result_var_df = ro.r('result_var_df')\n",
    "# res = ro.r('res')\n",
    "# print(res)\n",
    "\n",
    "# result_df = pandas2ri.rpy2py(result_df)\n",
    "# result_var_df = pandas2ri.rpy2py(result_var_df)\n",
    "# #print(\"Résultats de la FAMD :\\n\", result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 373 variables ont été conservés"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
