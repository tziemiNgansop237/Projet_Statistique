{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: 'Georgia', serif; text-align: center; font-size: 30px; color:rgb(52, 152, 219); text-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3)\">Préparation des données</h1>\n",
    "<br/>\n",
    "<br/>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-family: 'Georgia', serif; text-align: center; font-size: 25px; color:rgb(47, 99, 220)\">1- <u>reduction du nombre de variable de base_edu </u></h1>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/onyxia/work/Projet_Statistique\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_learner_id</th>\n",
       "      <th>days_between_signup_and_first_activity</th>\n",
       "      <th>days_between_order_and_first_activity</th>\n",
       "      <th>first_theory_activity_date</th>\n",
       "      <th>days_between_first_and_last_activities</th>\n",
       "      <th>chapter_before_success_count</th>\n",
       "      <th>serie_before_success_count</th>\n",
       "      <th>quiz_before_success_count</th>\n",
       "      <th>theory_activities_total</th>\n",
       "      <th>weekly_study_objective</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_weeks_weekly_study_objective_reached_80pct</th>\n",
       "      <th>nb_weeks_weekly_study_objective_reached_75pct</th>\n",
       "      <th>nb_weeks_weekly_study_objective_reached_70pct</th>\n",
       "      <th>nb_weeks_weekly_study_objective_not_reached</th>\n",
       "      <th>nb_weeks_no_activity</th>\n",
       "      <th>nb_weeks_no_weekly_study_objective</th>\n",
       "      <th>pct_study_objective_reached</th>\n",
       "      <th>pct_study_objective_not_reached</th>\n",
       "      <th>pct_study_objective_no_activity</th>\n",
       "      <th>pct_no_objective_weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3838161406066513919</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-17 15:00:23.000000</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5829430568065349352</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-07 12:02:53.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7677180318050051984</td>\n",
       "      <td>787</td>\n",
       "      <td>788</td>\n",
       "      <td>2022-05-10 01:35:49.000000</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5150597998144597550</td>\n",
       "      <td>615</td>\n",
       "      <td>616</td>\n",
       "      <td>2024-04-18 04:56:03.262330</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>969323468959211246</td>\n",
       "      <td>169</td>\n",
       "      <td>170</td>\n",
       "      <td>2019-03-19 12:32:56.000000</td>\n",
       "      <td>554</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 477 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_learner_id  days_between_signup_and_first_activity  \\\n",
       "0   3838161406066513919                                      41   \n",
       "1   5829430568065349352                                       0   \n",
       "2   7677180318050051984                                     787   \n",
       "3  -5150597998144597550                                     615   \n",
       "4    969323468959211246                                     169   \n",
       "\n",
       "   days_between_order_and_first_activity first_theory_activity_date  \\\n",
       "0                                      0 2017-12-17 15:00:23.000000   \n",
       "1                                      0 2022-07-07 12:02:53.000000   \n",
       "2                                    788 2022-05-10 01:35:49.000000   \n",
       "3                                    616 2024-04-18 04:56:03.262330   \n",
       "4                                    170 2019-03-19 12:32:56.000000   \n",
       "\n",
       "   days_between_first_and_last_activities  chapter_before_success_count  \\\n",
       "0                                     265                             0   \n",
       "1                                      27                             0   \n",
       "2                                     295                             0   \n",
       "3                                     138                             0   \n",
       "4                                     554                             0   \n",
       "\n",
       "   serie_before_success_count  quiz_before_success_count  \\\n",
       "0                           3                          0   \n",
       "1                           0                          0   \n",
       "2                           0                          0   \n",
       "3                           0                          0   \n",
       "4                           0                          0   \n",
       "\n",
       "   theory_activities_total  weekly_study_objective  ...  \\\n",
       "0                        3                    <NA>  ...   \n",
       "1                       11                    <NA>  ...   \n",
       "2                       73                     240  ...   \n",
       "3                       75                    <NA>  ...   \n",
       "4                       41                     120  ...   \n",
       "\n",
       "   nb_weeks_weekly_study_objective_reached_80pct  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   nb_weeks_weekly_study_objective_reached_75pct  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   nb_weeks_weekly_study_objective_reached_70pct  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   nb_weeks_weekly_study_objective_not_reached  nb_weeks_no_activity  \\\n",
       "0                                            0                     0   \n",
       "1                                            0                     0   \n",
       "2                                            1                     0   \n",
       "3                                            0                     0   \n",
       "4                                            1                     0   \n",
       "\n",
       "   nb_weeks_no_weekly_study_objective  pct_study_objective_reached  \\\n",
       "0                                   1                          0.0   \n",
       "1                                   1                          0.0   \n",
       "2                                   0                          0.0   \n",
       "3                                   1                          0.0   \n",
       "4                                   0                          0.0   \n",
       "\n",
       "   pct_study_objective_not_reached  pct_study_objective_no_activity  \\\n",
       "0                              0.0                              0.0   \n",
       "1                              0.0                              0.0   \n",
       "2                            100.0                              0.0   \n",
       "3                              0.0                              0.0   \n",
       "4                            100.0                              0.0   \n",
       "\n",
       "   pct_no_objective_weeks  \n",
       "0                   100.0  \n",
       "1                   100.0  \n",
       "2                     0.0  \n",
       "3                   100.0  \n",
       "4                     0.0  \n",
       "\n",
       "[5 rows x 477 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "print(os.getcwd())  # Répertoire actuel\n",
    "#repertoire de la bd\n",
    "url=\"/home/onyxia/work/Projet_Statistique/data/base_Edu.parquet\"\n",
    "#url=\"C:/Users/lisaw/Desktop/ENSAE/2AD/Projet-stat-ap/Donnees/base_Edu.parquet\"\n",
    "base_Edu=pd.read_parquet(url)\n",
    "base_Edu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 477 entries, unique_learner_id to pct_no_objective_weeks\n",
      "dtypes: Int64(72), boolean(254), datetime64[us](1), float64(150)\n",
      "memory usage: 450.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(base_Edu.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de données compte donc 477 variables dont 72 de type Int, 254 de type boolean, 1 de type datetime et 150 de type float soit au total 254 variables qualitatives (**boolean**) et 221 variables quantitatives(**float + int** en excluant les identifiants) sans oublier la variable de type **datetime**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "Nous commencons par épurer la base données avant de passer à la réduction de dimension. On s'intéressera aux valeurs manquantes. "
=======
    "Nous commencons par épurer la base données avant de passer à la réduction de dimension. On s'intéressera essentiellement ici aux données erronnées et valeurs manquantes. La nature de nos variables c'est à dire leur sens laisse supposer des valeurs négatives comme potentielles valeurs erronées pour nos variables numérique (int + float+ datetime). Aucune opération ne sera faite au niveau des booléen concernant les données erronées puisque leur type impose déjà les valeurs possibles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_learner_id                               0.49958\n",
      "days_between_order_and_first_activity           0.10299\n",
      "days_between_first_activity_and_exam            0.03113\n",
      "days_between_order_and_exam                     0.00052\n",
      "avg_self_assessment_gap                         0.24112\n",
      "exam_series_increment_avg                      0.217945\n",
      "delay_annulation_lesson_days_min               0.000025\n",
      "delay_annulation_lesson_days_avg               0.000015\n",
      "score_pct__mean_change                         0.228525\n",
      "score_pct__mean_second_derivative_central       0.45819\n",
      "score_pct__skewness                             0.57913\n",
      "score_pct__kurtosis                            0.398365\n",
      "score_pct__fft_aggregated__aggtype_kurtosis    0.001985\n",
      "score_pct__linear_trend__attr_intercept        0.000005\n",
      "score_pct__linear_trend__attr_slope            0.199035\n",
      "dtype: Float64\n",
      "Les types concernés par les valeurs négatives sont:  float64    10\n",
      "Int64       5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "neg=(base_Edu.select_dtypes(exclude=\"datetime\")<0).sum()/len(base_Edu)\n",
    "print(neg[neg>0])\n",
    "print(\"Les types concernés par les valeurs négatives sont: \",base_Edu[neg[neg>0].index].dtypes.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15 variables numériques présentent donc des valeurs négatives potentiellement erronnées.Ces valeurs négatives n'ont pas de raison d'être présentent dans la base.  Seul les variables de types **int** et **float** sont concernées. On laisse de coté la variable **unique_learner_id** qui représente l'identifiant de notre base qui ne nous sera d'ailleurs d'aucune utilité pour nos analyses. On pourrait penser à supprimer les observations correspondantes au valeurs manqantes. Mais cela entrainerait une perte considérable d'informations. La variable **score_pct__skewness** présente à elle seul 57%  de valeurs négatives. On risque donc de perdre environ 60% des observations voire plus si on décide de supprimer des observations associés. On choisit ici de remplacer ces valeurs par la médiane de la variable correspondante pour éviter de distordre significativement la structure de nos données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Récupération des variables concernées sauf l'identifiant\n",
    "neg=neg.drop(\"unique_learner_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4447/2017371698.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].apply(lambda x: median_without_negatives if x < 0 else x)\n",
      "/tmp/ipykernel_4447/2017371698.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].apply(lambda x: median_without_negatives if x < 0 else x)\n",
      "/tmp/ipykernel_4447/2017371698.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].apply(lambda x: median_without_negatives if x < 0 else x)\n",
      "/tmp/ipykernel_4447/2017371698.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].apply(lambda x: median_without_negatives if x < 0 else x)\n",
      "/tmp/ipykernel_4447/2017371698.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].apply(lambda x: median_without_negatives if x < 0 else x)\n",
      "/tmp/ipykernel_4447/2017371698.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].apply(lambda x: median_without_negatives if x < 0 else x)\n",
      "/tmp/ipykernel_4447/2017371698.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].apply(lambda x: median_without_negatives if x < 0 else x)\n",
      "/tmp/ipykernel_4447/2017371698.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].apply(lambda x: median_without_negatives if x < 0 else x)\n",
      "/tmp/ipykernel_4447/2017371698.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].apply(lambda x: median_without_negatives if x < 0 else x)\n",
      "/tmp/ipykernel_4447/2017371698.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].apply(lambda x: median_without_negatives if x < 0 else x)\n",
      "/tmp/ipykernel_4447/2017371698.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].apply(lambda x: median_without_negatives if x < 0 else x)\n",
      "/tmp/ipykernel_4447/2017371698.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].apply(lambda x: median_without_negatives if x < 0 else x)\n",
      "/tmp/ipykernel_4447/2017371698.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].apply(lambda x: median_without_negatives if x < 0 else x)\n",
      "/tmp/ipykernel_4447/2017371698.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = df[column].apply(lambda x: median_without_negatives if x < 0 else x)\n"
     ]
    }
   ],
   "source": [
    "def replace_negatives_with_median(df):\n",
    "    # Filtrer uniquement les colonnes numériques\n",
    "    numerical_df = df.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Remplacer les valeurs négatives par la médiane\n",
    "    for column in numerical_df.columns:\n",
    "        # Calculer la médiane sans les valeurs négatives\n",
    "        median_without_negatives = numerical_df.loc[numerical_df[column] >= 0, column].median()\n",
    "        \n",
    "        # Remplacer les valeurs négatives par cette médiane\n",
    "        df[column] = df[column].apply(lambda x: median_without_negatives if x < 0 else x)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Application de la fonction\n",
    "base_Edu[neg[neg>0].index] = replace_negatives_with_median(base_Edu[neg[neg>0].index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interessons nous maintenant aux valeurs manquantes. "
>>>>>>> de378ea1d08df7570a5570aa6e672c2c15254d2e
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    404.000000\n",
       "mean       0.743390\n",
       "std        0.279055\n",
       "min        0.047720\n",
       "25%        0.666710\n",
       "50%        0.842345\n",
       "75%        0.918625\n",
       "max        1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value=(base_Edu.isnull().sum()/len(base_Edu))\n",
    "missing_value[missing_value>0]\n",
    "missing_value[missing_value>0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de données comporte donc 404 variables avec valeurs manquantes sur le total des 476 variables de la base ce qui n'est pas du tout négligeable. Voyons combien de valeurs manquantes at-on par type de variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45  variable de type int ont des valeurs manquantes\n",
      "106  variable de type float ont des valeurs manquantes\n",
      "253  variable de type boolean ont des valeurs manquantes\n",
      "0  variable de type datetime ont des valeurs manquantes\n"
     ]
    }
   ],
   "source": [
    "print(base_Edu.select_dtypes(\"int\").isnull().any().sum(),\" variables de type int ont des valeurs manquantes\")\n",
    "print(base_Edu.select_dtypes(\"float\").isnull().any().sum(),\" variables de type float ont des valeurs manquantes\")\n",
    "print(base_Edu.select_dtypes(\"boolean\").isnull().any().sum(),\" variables de type boolean ont des valeurs manquantes\")\n",
    "print(base_Edu.select_dtypes(\"datetime\").isnull().any().sum(),\" variables de type datetime ont des valeurs manquantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La seule variable de type datetime n'a donc pas de valeurs manquantes.  Analysons de plus près les proportions de valeurs manquantes des autres types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    253.000000\n",
       "mean       0.903116\n",
       "std        0.072136\n",
       "min        0.695085\n",
       "25%        0.837765\n",
       "50%        0.883305\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_bool=base_Edu.select_dtypes(\"boolean\").isnull().sum()/len(base_Edu)\n",
    "miss_bool[miss_bool>0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les variables de type boolean comporte pratiquement tous assez de valeurs manquantes avec un minimum de 69% et un maximum de 100% du total des observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs manquantes de la base ne sont pas complètement aléatoires. Elles ne sont pas pour la plupart le fruit d'une mauvaise collecte de données. La présence de valeurs manquantes dans cette base est due à diverses raisons notamment le fait que plusieurs individus de la base n'ont pas encore passé d'examen pour le permis. Plusieurs questions(variables) n'ont de sens que dans le cas où le premier examen est passé. Il y a donc une part d'information apporté par ces valeurs manquantes que nous devons inclure dans nos analyses. Pour les variables booléenne, nous pouvons régler ce prblème c'est à dire prendre en compte l'information apportée par ces valeurs manquantes en transformant les variables booléennes en variable catégorielles en considérant les valeurs manquantes comme une catégorie(True=1,False=0 et NA=2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(base_Edu.select_dtypes('category'))\n",
    "def encode_column_with_na(col):\n",
    "    mapping = {True: 1, False: 0, pd.NA: 2}  # Encoder les valeurs booléennes et <NA>\n",
    "    return col.map(mapping)\n",
    "colboo=base_Edu.select_dtypes(\"boolean\").columns\n",
    "for col in colboo:\n",
    "    base_Edu[col] = encode_column_with_na(base_Edu[col]).astype(\"category\")\n",
    "#base_Edu[\"is_first_exam_success\"].cat.categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passons maintenant aux variables quantitatives (int+float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    151.000000\n",
       "mean       0.475770\n",
       "std        0.292138\n",
       "min        0.047720\n",
       "25%        0.184915\n",
       "50%        0.483995\n",
       "75%        0.736010\n",
       "max        0.941710\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_quant=base_Edu.select_dtypes(include=[\"int\",\"float\"]).isnull().sum()/len(base_Edu)\n",
    "miss_quant[miss_quant>0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les variables quantitatives, la distribution des valeurs manquantes est plus étendue. On enregistre 151 variables qualitatives avec valeurs manquantes. On a un minimum de 4% et un maximum de 94% de valeurs manquantes par rapport au total d'observation(nous rappelons 200000 obervations). La nature des variables et la distribution des valeurs manquantes dans ce cas ne facilite pas la capture de l'information apportée par la présence de ces valeurs manquantes. On pourrait opter pour une imputation par KNN ou par imputation itérative (MICE) mais cela risque de modifier et significativement les corrélations existant déjà entre les variables introduisant ainsi un important biais et au vue de la taille de l'echantillon, cela demanderait un temps d'excution énorme. On choisit ici donc de procéder à une imputation par la médiane après suppression des variables avant un taux élevé de valeurs manquantes pour minimiser le biais. Cela permettra de ne pas trop distordre les distributions existentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    118.000000\n",
       "mean       0.054362\n",
       "std        0.074368\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.106310\n",
       "max        0.194530\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_quant[miss_quant<=0.20].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous choisissons le seuil de 20% de valeurs manquantes. Ce seuil nous parait raisonnable puisqu'il est relativement faible et n'entraine pas la suppression d'un grand nombre de variables quantitatives (118 sont conservées sur un total de 151)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppression des variables avec plus de 20% de valeurs manquantes\n",
    "base_Edu=base_Edu.drop(columns=miss_quant[miss_quant>0.20].index)\n",
    "#Imputation par la médiane\n",
    "col=base_Edu.select_dtypes(exclude='category').columns\n",
    "base_Edu[col] = base_Edu[col].fillna(base_Edu[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_learner_id</th>\n",
       "      <th>days_between_signup_and_first_activity</th>\n",
       "      <th>days_between_order_and_first_activity</th>\n",
       "      <th>first_theory_activity_date</th>\n",
       "      <th>days_between_first_and_last_activities</th>\n",
       "      <th>chapter_before_success_count</th>\n",
       "      <th>serie_before_success_count</th>\n",
       "      <th>quiz_before_success_count</th>\n",
       "      <th>theory_activities_total</th>\n",
       "      <th>is_first_exam_success</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_weeks_weekly_study_objective_reached_80pct</th>\n",
       "      <th>nb_weeks_weekly_study_objective_reached_75pct</th>\n",
       "      <th>nb_weeks_weekly_study_objective_reached_70pct</th>\n",
       "      <th>nb_weeks_weekly_study_objective_not_reached</th>\n",
       "      <th>nb_weeks_no_activity</th>\n",
       "      <th>nb_weeks_no_weekly_study_objective</th>\n",
       "      <th>pct_study_objective_reached</th>\n",
       "      <th>pct_study_objective_not_reached</th>\n",
       "      <th>pct_study_objective_no_activity</th>\n",
       "      <th>pct_no_objective_weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3838161406066513919</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-12-17 15:00:23.000000</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5829430568065349352</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-07-07 12:02:53.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7677180318050051984</td>\n",
       "      <td>787</td>\n",
       "      <td>788.0</td>\n",
       "      <td>2022-05-10 01:35:49.000000</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5150597998144597550</td>\n",
       "      <td>615</td>\n",
       "      <td>616.0</td>\n",
       "      <td>2024-04-18 04:56:03.262330</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>969323468959211246</td>\n",
       "      <td>169</td>\n",
       "      <td>170.0</td>\n",
       "      <td>2019-03-19 12:32:56.000000</td>\n",
       "      <td>554</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 373 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_learner_id  days_between_signup_and_first_activity  \\\n",
       "0   3838161406066513919                                      41   \n",
       "1   5829430568065349352                                       0   \n",
       "2   7677180318050051984                                     787   \n",
       "3  -5150597998144597550                                     615   \n",
       "4    969323468959211246                                     169   \n",
       "\n",
       "   days_between_order_and_first_activity first_theory_activity_date  \\\n",
       "0                                    0.0 2017-12-17 15:00:23.000000   \n",
       "1                                    0.0 2022-07-07 12:02:53.000000   \n",
       "2                                  788.0 2022-05-10 01:35:49.000000   \n",
       "3                                  616.0 2024-04-18 04:56:03.262330   \n",
       "4                                  170.0 2019-03-19 12:32:56.000000   \n",
       "\n",
       "   days_between_first_and_last_activities  chapter_before_success_count  \\\n",
       "0                                     265                             0   \n",
       "1                                      27                             0   \n",
       "2                                     295                             0   \n",
       "3                                     138                             0   \n",
       "4                                     554                             0   \n",
       "\n",
       "   serie_before_success_count  quiz_before_success_count  \\\n",
       "0                           3                          0   \n",
       "1                           0                          0   \n",
       "2                           0                          0   \n",
       "3                           0                          0   \n",
       "4                           0                          0   \n",
       "\n",
       "   theory_activities_total is_first_exam_success  ...  \\\n",
       "0                        3                     0  ...   \n",
       "1                       11                     2  ...   \n",
       "2                       73                     0  ...   \n",
       "3                       75                     2  ...   \n",
       "4                       41                     2  ...   \n",
       "\n",
       "   nb_weeks_weekly_study_objective_reached_80pct  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   nb_weeks_weekly_study_objective_reached_75pct  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   nb_weeks_weekly_study_objective_reached_70pct  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   nb_weeks_weekly_study_objective_not_reached  nb_weeks_no_activity  \\\n",
       "0                                            0                     0   \n",
       "1                                            0                     0   \n",
       "2                                            1                     0   \n",
       "3                                            0                     0   \n",
       "4                                            1                     0   \n",
       "\n",
       "   nb_weeks_no_weekly_study_objective  pct_study_objective_reached  \\\n",
       "0                                   1                          0.0   \n",
       "1                                   1                          0.0   \n",
       "2                                   0                          0.0   \n",
       "3                                   1                          0.0   \n",
       "4                                   0                          0.0   \n",
       "\n",
       "   pct_study_objective_not_reached  pct_study_objective_no_activity  \\\n",
       "0                              0.0                              0.0   \n",
       "1                              0.0                              0.0   \n",
       "2                            100.0                              0.0   \n",
       "3                              0.0                              0.0   \n",
       "4                            100.0                              0.0   \n",
       "\n",
       "   pct_no_objective_weeks  \n",
       "0                   100.0  \n",
       "1                   100.0  \n",
       "2                     0.0  \n",
       "3                   100.0  \n",
       "4                     0.0  \n",
       "\n",
       "[5 rows x 373 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_Edu.isnull().any().sum()\n",
    "base_Edu.to_csv(\"base_Edu_reduced.csv\", index=False)\n",
    "base_Edu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus aucune valeur manquante. La base de données enfin prête, on peut passer aux opérations de réduction de dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<p style=\"font-family: 'Georgia', serif; text-align: center;color:rgb(47, 99, 220);font-size: 25px\">\n",
    "<u>\n",
    "Reduction Via une FAMD</u>\n",
    "</p>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting prince\n",
      "  Downloading prince-0.15.0-py3-none-any.whl.metadata (641 bytes)\n",
      "Collecting altair<6.0.0,>=5.0.0 (from prince)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from prince) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.5.1 in /opt/conda/lib/python3.12/site-packages (from prince) (1.6.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from altair<6.0.0,>=5.0.0->prince) (3.1.5)\n",
      "Collecting jsonschema>=3.0 (from altair<6.0.0,>=5.0.0->prince)\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair<6.0.0,>=5.0.0->prince)\n",
      "  Downloading narwhals-1.23.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from altair<6.0.0,>=5.0.0->prince) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from altair<6.0.0,>=5.0.0->prince) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas<3.0.0,>=2.2.0->prince) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas<3.0.0,>=2.2.0->prince) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas<3.0.0,>=2.2.0->prince) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas<3.0.0,>=2.2.0->prince) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn<2.0.0,>=1.5.1->prince) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn<2.0.0,>=1.5.1->prince) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn<2.0.0,>=1.5.1->prince) (3.5.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6.0.0,>=5.0.0->prince) (24.3.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6.0.0,>=5.0.0->prince)\n",
      "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6.0.0,>=5.0.0->prince)\n",
      "  Downloading referencing-0.36.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6.0.0,>=5.0.0->prince)\n",
      "  Downloading rpds_py-0.22.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.2.0->prince) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->altair<6.0.0,>=5.0.0->prince) (3.0.2)\n",
      "Downloading prince-0.15.0-py3-none-any.whl (417 kB)\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading narwhals-1.23.0-py3-none-any.whl (306 kB)\n",
      "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading referencing-0.36.1-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.22.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "Installing collected packages: rpds-py, narwhals, referencing, jsonschema-specifications, jsonschema, altair, prince\n",
      "Successfully installed altair-5.5.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 narwhals-1.23.0 prince-0.15.0 referencing-0.36.1 rpds-py-0.22.3\n"
     ]
    }
   ],
   "source": [
    "!pip install prince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 373 entries, unique_learner_id to pct_no_objective_weeks\n",
      "dtypes: Int64(46), category(254), datetime64[us](1), float64(72)\n",
      "memory usage: 238.8 MB\n"
     ]
    }
   ],
   "source": [
    "base_Edu.info()\n",
    "base_Edu_sample = base_Edu.sample(n=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prince\n",
    "famd = prince.FAMD(\n",
    "    n_components=2,\n",
    "    n_iter=2,\n",
    "    copy=True,\n",
    "    check_input=True,\n",
    "    random_state=42,\n",
    "    engine=\"sklearn\",\n",
    "    handle_unknown=\"error\"  # same parameter as sklearn.preprocessing.OneHotEncoder\n",
    ")\n",
    "\n",
    "famd = famd.fit(base_Edu_sample.head(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "famd.eigenvalues_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "famd.row_coordinates(base_Edu_sample.head(10000)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "famd.column_coordinates_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    famd.row_contributions_\n",
    "    .sort_values(0, ascending=False)\n",
    "    .head(5)\n",
    "    .style.format('{:.3%}')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colonnes supprimées\n",
    "print(\"les variables suivantes ont été supprimées: \")\n",
    "famd.column_contributions_.style.format('{:.0%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 373 variables ont été conservés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#les var supprimées en vert et les var conservées en bleus\n",
    "\n",
    "famd.plot(\n",
    "    base_Edu_sample.head(10000),\n",
    "    x_component=0,\n",
    "    y_component=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
